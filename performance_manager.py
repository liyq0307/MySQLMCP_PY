"""
MySQLæ€§èƒ½ç®¡ç†å™¨ - ä¼ä¸šçº§æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆ

ç»Ÿä¸€ç®¡ç†å’Œä¼˜åŒ–MySQLæ•°æ®åº“æ€§èƒ½çš„ç»¼åˆæ€§å·¥å…·ï¼Œé›†æˆäº†æ…¢æŸ¥è¯¢åˆ†æã€ç´¢å¼•ä¼˜åŒ–ã€
æŸ¥è¯¢æ€§èƒ½å‰–æã€ç³»ç»Ÿç›‘æ§å’ŒæŠ¥å‘Šç”Ÿæˆç­‰å…¨æ–¹ä½æ€§èƒ½ç®¡ç†åŠŸèƒ½ã€‚

æ ¸å¿ƒæ¨¡å—é›†æˆï¼š
- æ…¢æŸ¥è¯¢åˆ†ææ¨¡å—ï¼šåˆ†ææ…¢æŸ¥è¯¢æ—¥å¿—å’Œæ€§èƒ½æ¨¡å¼æ•°æ®
- ç´¢å¼•ä¼˜åŒ–æ¨¡å—ï¼šç”Ÿæˆç´¢å¼•ä¼˜åŒ–å»ºè®®å’Œå¥åº·æ£€æŸ¥
- æŸ¥è¯¢æ€§èƒ½å‰–ææ¨¡å—ï¼šåˆ†æå•ä¸ªSQLæŸ¥è¯¢çš„æ‰§è¡Œè®¡åˆ’
- æ€§èƒ½ç›‘æ§æ¨¡å—ï¼šæŒç»­ç›‘æ§æ•°æ®åº“æ€§èƒ½æŒ‡æ ‡
- æŠ¥å‘Šç”Ÿæˆæ¨¡å—ï¼šç”Ÿæˆç»¼åˆæ€§èƒ½æŠ¥å‘Šå’Œä¼˜åŒ–å»ºè®®

@fileoverview MySQLæ€§èƒ½ç®¡ç†çš„ç»Ÿä¸€è§£å†³æ–¹æ¡ˆ
@author liyq
@version 1.0.0
@since 1.0.0
@updated 2025-09-25
@license MIT
"""

import asyncio
import re
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional
from dataclasses import dataclass

from type_utils import (
    MySQLMCPError,
    ErrorCategory,
    ErrorSeverity
)
from logger import logger
from mysql_manager import MySQLManager


# =============================================================================
# æ€§èƒ½ç®¡ç†å™¨ç›¸å…³ç±»å‹å®šä¹‰
# =============================================================================

@dataclass
class IndexSuggestion:
    """ç´¢å¼•å»ºè®®ä¿¡æ¯"""
    table: str
    columns: List[str]
    index_type: str  # 'PRIMARY', 'UNIQUE', 'INDEX', 'FULLTEXT', 'SPATIAL'
    expected_improvement: str
    priority: str  # 'HIGH', 'MEDIUM', 'LOW'
    reason: str


@dataclass
class QueryProfileResult:
    """æŸ¥è¯¢å‰–æç»“æœ"""
    explain_result: List[Dict[str, Any]]
    execution_stats: Dict[str, Any]
    recommendations: List[str]
    performance_score: float


@dataclass
class SlowQueryInfo:
    """æ…¢æŸ¥è¯¢ä¿¡æ¯"""
    sql_text: str
    execution_time: float
    lock_time: float
    rows_examined: int
    rows_returned: int
    start_time: datetime
    user: str
    database: str
    ip_address: str
    thread_id: int
    uses_index: bool


@dataclass
class SlowQueryAnalysis:
    """æ…¢æŸ¥è¯¢åˆ†æç»“æœ"""
    total_slow_queries: int
    slowest_query: Optional[SlowQueryInfo]
    average_execution_time: float
    common_patterns: List[Dict[str, Any]]
    index_suggestions: List[IndexSuggestion]
    performance_issues: List[str]
    recommendations: List[str]


@dataclass
class PerformanceReport:
    """æ€§èƒ½æŠ¥å‘Šç»“æœ"""
    generated_at: datetime
    summary: Dict[str, Any]
    slow_query_analysis: SlowQueryAnalysis
    system_status: Dict[str, Any]
    recommendations: List[str]


@dataclass
class PerformanceAnalysisConfig:
    """æ€§èƒ½åˆ†æé…ç½®é€‰é¡¹"""
    long_query_time: Optional[float] = 1.0
    time_range: Optional[int] = 1
    include_details: Optional[bool] = True
    limit: Optional[int] = 100
    min_examined_row_limit: Optional[int] = 1000
    enable_performance_schema: Optional[bool] = True
    log_queries_not_using_indexes: Optional[bool] = True
    max_log_file_size: Optional[int] = 100
    log_slow_admin_statements: Optional[bool] = True
    slow_query_log_file: Optional[str] = None


@dataclass
class SlowQueryConfig:
    """æ…¢æŸ¥è¯¢é…ç½®é€‰é¡¹"""
    long_query_time: Optional[float] = 1.0
    log_queries_not_using_indexes: Optional[bool] = True
    min_examined_row_limit: Optional[int] = 1000
    max_log_file_size: Optional[int] = 100
    log_slow_admin_statements: Optional[bool] = True
    slow_query_log_file: Optional[str] = None
    enable_performance_schema: Optional[bool] = True


# =============================================================================
# æ…¢æŸ¥è¯¢åˆ†ææ¨¡å—
# =============================================================================

class SlowQueryAnalysisModule:
    """
    æ…¢æŸ¥è¯¢åˆ†ææ¨¡å—

    ä¸“é—¨ç”¨äºåˆ†æMySQLæ…¢æŸ¥è¯¢æ—¥å¿—å’Œæ€§èƒ½æ¨¡å¼æ•°æ®çš„æ¨¡å—ï¼Œèƒ½å¤Ÿè¯†åˆ«æ€§èƒ½ç“¶é¢ˆã€
    åˆ†ææŸ¥è¯¢æ¨¡å¼å¹¶æä¾›ä¼˜åŒ–å»ºè®®ã€‚é€šè¿‡åˆ†æperformance_schemaä¸­çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œ
    æä¾›è¯¦ç»†çš„æ…¢æŸ¥è¯¢åˆ†ææŠ¥å‘Šã€‚
    """

    def __init__(self, mysql_manager: MySQLManager, config: PerformanceAnalysisConfig = None):
        """åˆå§‹åŒ–æ…¢æŸ¥è¯¢åˆ†ææ¨¡å—"""
        self.mysql_manager = mysql_manager
        self.config = config or PerformanceAnalysisConfig()

    async def enable_slow_query_log(self, config: SlowQueryConfig = None) -> bool:
        """
        å¯ç”¨æ…¢æŸ¥è¯¢æ—¥å¿—

        é…ç½®MySQLæœåŠ¡å™¨å¯ç”¨æ…¢æŸ¥è¯¢æ—¥å¿—è®°å½•åŠŸèƒ½ã€‚

        Args:
            config: æ…¢æŸ¥è¯¢é…ç½®å‚æ•°

        Returns:
            bool: é…ç½®æ˜¯å¦æˆåŠŸ
        """
        effective_config = {**self.config.__dict__, **(config.__dict__ if config else {})}

        try:
            # æ£€æŸ¥ç”¨æˆ·æƒé™
            await self._check_user_privileges()

            # è®¾ç½®æ…¢æŸ¥è¯¢ç›¸å…³å‚æ•°
            settings = [
                "SET GLOBAL slow_query_log = 'ON'",
                f"SET GLOBAL long_query_time = {effective_config.get('long_query_time', 1)}",
                f"SET GLOBAL log_queries_not_using_indexes = '{effective_config.get('log_queries_not_using_indexes', True) and 'ON' or 'OFF'}'",
                f"SET GLOBAL min_examined_row_limit = {effective_config.get('min_examined_row_limit', 1000)}",
                f"SET GLOBAL log_slow_admin_statements = '{effective_config.get('log_slow_admin_statements', True) and 'ON' or 'OFF'}'"
            ]

            if effective_config.get('slow_query_log_file'):
                settings.append(f"SET GLOBAL slow_query_log_file = '{effective_config['slow_query_log_file']}'")

            # æ‰¹é‡æ‰§è¡Œé…ç½®
            for setting in settings:
                await self.mysql_manager.execute_query(setting)

            # éªŒè¯é…ç½®æ˜¯å¦ç”Ÿæ•ˆ
            verify_query = """
                SELECT
                    @@slow_query_log as slow_query_log_enabled,
                    @@long_query_time as long_query_time,
                    @@log_queries_not_using_indexes as log_queries_not_using_indexes,
                    @@min_examined_row_limit as min_examined_row_limit
            """

            verify_result = await self.mysql_manager.execute_query(verify_query)
            settings_verified = verify_result[0] if verify_result else {}

            if not settings_verified.get('slow_query_log_enabled'):
                raise MySQLMCPError(
                    "æ…¢æŸ¥è¯¢æ—¥å¿—å¯ç”¨å¤±è´¥",
                    ErrorCategory.SLOW_QUERY_LOG_ERROR,
                    ErrorSeverity.HIGH
                )

            # æ›´æ–°é…ç½®
            if config:
                self.config = PerformanceAnalysisConfig(**{**self.config.__dict__, **config.__dict__})

            logger.info("âœ… æ…¢æŸ¥è¯¢æ—¥å¿—å·²æˆåŠŸå¯ç”¨")
            return True

        except Exception as e:
            raise MySQLMCPError(
                f"å¯ç”¨æ…¢æŸ¥è¯¢æ—¥å¿—å¤±è´¥: {str(e)}",
                ErrorCategory.SLOW_QUERY_CONFIGURATION_ERROR,
                ErrorSeverity.HIGH
            )

    async def disable_slow_query_log(self) -> bool:
        """ç¦ç”¨æ…¢æŸ¥è¯¢æ—¥å¿—"""
        try:
            await self.mysql_manager.execute_query("SET GLOBAL slow_query_log = 'OFF'")
            logger.info("â¹ï¸ æ…¢æŸ¥è¯¢æ—¥å¿—å·²ç¦ç”¨")
            return True
        except Exception as e:
            raise MySQLMCPError(
                f"ç¦ç”¨æ…¢æŸ¥è¯¢æ—¥å¿—å¤±è´¥: {str(e)}",
                ErrorCategory.SLOW_QUERY_CONFIGURATION_ERROR,
                ErrorSeverity.MEDIUM
            )

    async def get_slow_query_log_config(self) -> SlowQueryConfig:
        """è·å–æ…¢æŸ¥è¯¢æ—¥å¿—é…ç½®"""
        try:
            query = """
                SELECT
                    @@slow_query_log as slowQueryLog,
                    @@long_query_time as longQueryTime,
                    @@log_queries_not_using_indexes as logQueriesNotUsingIndexes,
                    @@min_examined_row_limit as minExaminedRowLimit,
                    @@slow_query_log_file as slowQueryLogFile,
                    @@log_slow_admin_statements as logSlowAdminStatements
            """

            result = await self.mysql_manager.execute_query(query)
            return SlowQueryConfig(**result[0]) if result else SlowQueryConfig()
        except Exception as e:
            raise MySQLMCPError(
                f"è·å–æ…¢æŸ¥è¯¢æ—¥å¿—é…ç½®å¤±è´¥: {str(e)}",
                ErrorCategory.DATA_ERROR,
                ErrorSeverity.LOW
            )

    async def get_slow_query_log_status(self) -> Dict[str, Any]:
        """è·å–æ…¢æŸ¥è¯¢æ—¥å¿—çŠ¶æ€"""
        try:
            queries = [
                'SELECT @@slow_query_log as enabled',
                'SELECT @@slow_query_log_file as log_file',
                'SELECT @@long_query_time as threshold_seconds',
                'SELECT @@log_queries_not_using_indexes as log_no_index',
                'SELECT @@min_examined_row_limit as min_rows',
                'SELECT @@log_slow_admin_statements as log_admin'
            ]

            results = {}
            for i, query in enumerate(queries):
                try:
                    result = await self.mysql_manager.execute_query(query)
                    if result:
                        results.update(result[0])
                except Exception as e:
                    logger.warning(f"è·å–çŠ¶æ€ä¿¡æ¯å¤±è´¥ ({i}): {str(e)}")

            return results
        except Exception as e:
            raise MySQLMCPError(
                f"è·å–æ…¢æŸ¥è¯¢æ—¥å¿—çŠ¶æ€å¤±è´¥: {str(e)}",
                ErrorCategory.DATA_ERROR,
                ErrorSeverity.LOW
            )

    async def analyze_slow_queries(self, limit: int = 100, time_range: str = '1 day') -> SlowQueryAnalysis:
        """
        åˆ†ææ…¢æŸ¥è¯¢æ—¥å¿—

        é€šè¿‡æŸ¥è¯¢performance_schema.events_statements_summary_by_digestè¡¨ï¼Œ
        åˆ†ææ…¢æŸ¥è¯¢çš„æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯ï¼Œè¯†åˆ«æ€§èƒ½ç“¶é¢ˆå’Œå¸¸è§æŸ¥è¯¢æ¨¡å¼ã€‚

        Args:
            limit: é™åˆ¶è¿”å›çš„æ…¢æŸ¥è¯¢æ•°é‡ï¼Œé»˜è®¤ä¸º100
            time_range: åˆ†ææ—¶é—´èŒƒå›´ï¼Œé»˜è®¤ä¸º1å¤©

        Returns:
            SlowQueryAnalysis: æ…¢æŸ¥è¯¢åˆ†æç»“æœ
        """
        try:
            # æ£€æŸ¥performance_schemaæ˜¯å¦å¯ç”¨
            await self._check_performance_schema()

            # æ„å»ºæ—¶é—´èŒƒå›´æ¡ä»¶
            time_filter = self._build_time_filter(time_range)

            # æŸ¥è¯¢æ…¢æŸ¥è¯¢ç»Ÿè®¡ä¿¡æ¯
            query = f"""
                SELECT
                    DIGEST_TEXT as sql_text,
                    COUNT_STAR as execution_count,
                    SUM_TIMER_WAIT / 1000000000 as total_time_sec,
                    AVG_TIMER_WAIT / 1000000000 as avg_time_sec,
                    MAX_TIMER_WAIT / 1000000000 as max_time_sec,
                    FIRST_SEEN as first_seen,
                    LAST_SEEN as last_seen,
                    SCHEMA_NAME as database_name,
                    SUM_ROWS_EXAMINED as total_rows_examined,
                    SUM_ROWS_SENT as total_rows_sent,
                    SUM_NO_INDEX_USED + SUM_NO_GOOD_INDEX_USED as queries_without_index,
                    DIGEST as query_digest
                FROM performance_schema.events_statements_summary_by_digest
                WHERE
                    SCHEMA_NAME IS NOT NULL
                    AND DIGEST_TEXT IS NOT NULL
                    AND AVG_TIMER_WAIT > {(self.config.long_query_time or 1)} * 1000000000
                    {time_filter}
                ORDER BY AVG_TIMER_WAIT DESC
                LIMIT {limit}
            """

            slow_queries = await self.mysql_manager.execute_query(query)

            if not slow_queries:
                return self._create_empty_analysis()

            # è½¬æ¢æ ¼å¼å¹¶åˆ†æ
            query_infos = []
            for row in slow_queries:
                query_info = SlowQueryInfo(
                    sql_text=row.get('sql_text', ''),
                    execution_time=row.get('avg_time_sec', 0),
                    lock_time=0,
                    rows_examined=int(row.get('total_rows_examined', 0) / max(row.get('execution_count', 1), 1)),
                    rows_returned=int(row.get('total_rows_sent', 0) / max(row.get('execution_count', 1), 1)),
                    start_time=datetime.now(),
                    user='N/A',
                    database=row.get('database_name', 'unknown'),
                    ip_address='N/A',
                    thread_id=0,
                    uses_index=row.get('queries_without_index', 0) == 0
                )
                query_infos.append(query_info)

            # ç”Ÿæˆå®Œæ•´åˆ†æç»“æœ
            return self._generate_analysis_result(query_infos, slow_queries)

        except Exception as e:
            raise MySQLMCPError(
                f"æ…¢æŸ¥è¯¢åˆ†æå¤±è´¥: {str(e)}",
                ErrorCategory.SLOW_QUERY_ANALYSIS_ERROR,
                ErrorSeverity.MEDIUM
            )

    async def get_active_slow_queries(self) -> List[SlowQueryInfo]:
        """
        è·å–æ´»è·ƒçš„æ…¢æŸ¥è¯¢

        æŸ¥è¯¢information_schema.processlistè¡¨ï¼Œè·å–å½“å‰æ­£åœ¨æ‰§è¡Œçš„æ…¢æŸ¥è¯¢ã€‚
        """
        try:
            query = f"""
                SELECT
                    info AS sql_text,
                    TIME AS execution_time,
                    COMMAND AS command_type,
                    STATE AS current_state,
                    DB AS database_name,
                    HOST AS client_host,
                    ID AS thread_id
                FROM information_schema.processlist
                WHERE TIME > {(self.config.long_query_time or 1)}
                    AND COMMAND != 'Sleep'
                ORDER BY TIME DESC
                LIMIT 50
            """

            result = await self.mysql_manager.execute_query(query)

            active_queries = []
            for row in result:
                query_info = SlowQueryInfo(
                    sql_text=row.get('sql_text', ''),
                    execution_time=row.get('execution_time', 0),
                    lock_time=0,
                    rows_examined=0,
                    rows_returned=0,
                    start_time=datetime.now() - timedelta(seconds=row.get('execution_time', 0)),
                    user=row.get('client_host', '').split('@')[0] if row.get('client_host') else '',
                    database=row.get('database_name', ''),
                    ip_address=row.get('client_host', '').split('@')[1] if row.get('client_host') else '',
                    thread_id=row.get('thread_id', 0),
                    uses_index=False
                )
                active_queries.append(query_info)

            return active_queries

        except Exception as e:
            raise MySQLMCPError(
                f"è·å–æ´»è·ƒæ…¢æŸ¥è¯¢å¤±è´¥: {str(e)}",
                ErrorCategory.DATA_ERROR,
                ErrorSeverity.LOW
            )

    async def _check_user_privileges(self) -> None:
        """æ£€æŸ¥ç”¨æˆ·æƒé™"""
        try:
            await self.mysql_manager.execute_query("SELECT @@version")
        except Exception as e:
            if "Access denied" in str(e):
                raise MySQLMCPError(
                    "ç”¨æˆ·æ²¡æœ‰è¶³å¤Ÿçš„æƒé™é…ç½®æ…¢æŸ¥è¯¢æ—¥å¿—ï¼Œéœ€è¦SUPERæƒé™æˆ–ç›¸åº”æƒé™",
                    ErrorCategory.PRIVILEGE_ERROR,
                    ErrorSeverity.HIGH
                )
            raise

    async def _check_performance_schema(self) -> None:
        """æ£€æŸ¥æ€§èƒ½æ¨¡å¼æ˜¯å¦å¯ç”¨"""
        try:
            result = await self.mysql_manager.execute_query("SELECT @@performance_schema as enabled")
            enabled = result[0].get('enabled', 0) if result else 0

            if not enabled:
                raise MySQLMCPError(
                    "performance_schemaæœªå¯ç”¨ï¼Œæ— æ³•è¿›è¡Œæ…¢æŸ¥è¯¢åˆ†æã€‚éœ€è¦å¯ç”¨performance_schemaä»¥è·å¾—è¯¦ç»†çš„æŸ¥è¯¢ç»Ÿè®¡ä¿¡æ¯ã€‚",
                    ErrorCategory.CONFIGURATION_ERROR,
                    ErrorSeverity.MEDIUM
                )
        except Exception as e:
            raise MySQLMCPError(
                f"æ£€æŸ¥performance_schemaçŠ¶æ€å¤±è´¥: {str(e)}",
                ErrorCategory.CONFIGURATION_ERROR,
                ErrorSeverity.MEDIUM
            )

    def _build_time_filter(self, time_range: str) -> str:
        """æ„å»ºæ—¶é—´èŒƒå›´è¿‡æ»¤æ¡ä»¶"""
        return f"AND LAST_SEEN >= DATE_SUB(NOW(), INTERVAL {time_range})" if time_range else ""

    def _create_empty_analysis(self) -> SlowQueryAnalysis:
        """åˆ›å»ºç©ºçš„æ…¢æŸ¥è¯¢åˆ†æç»“æœ"""
        return SlowQueryAnalysis(
            total_slow_queries=0,
            slowest_query=None,
            average_execution_time=0.0,
            common_patterns=[],
            index_suggestions=[],
            performance_issues=[],
            recommendations=["æœªå‘ç°æ…¢æŸ¥è¯¢è®°å½•"]
        )

    def _generate_analysis_result(self, query_infos: List[SlowQueryInfo], raw_queries: List[Dict[str, Any]]) -> SlowQueryAnalysis:
        """ç”Ÿæˆå®Œæ•´çš„åˆ†æç»“æœ"""
        if not query_infos:
            return self._create_empty_analysis()

        total_time = sum(q.execution_time for q in query_infos)
        avg_time = total_time / len(query_infos)

        # åˆ†ææŸ¥è¯¢æ¨¡å¼
        pattern_count = {}
        for query in query_infos:
            pattern = self._extract_query_pattern(query.sql_text)
            if pattern not in pattern_count:
                pattern_count[pattern] = {"count": 0, "total_time": 0}
            pattern_count[pattern]["count"] += 1
            pattern_count[pattern]["total_time"] += query.execution_time

        common_patterns = [
            {
                "pattern": pattern,
                "count": stats["count"],
                "avg_time": stats["total_time"] / stats["count"]
            }
            for pattern, stats in pattern_count.items()
        ]
        common_patterns.sort(key=lambda x: x["count"], reverse=True)
        common_patterns = common_patterns[:10]

        # ç”Ÿæˆç´¢å¼•å»ºè®®
        index_suggestions = self._generate_index_suggestions(query_infos)

        # è¯†åˆ«æ€§èƒ½é—®é¢˜
        performance_issues = self._identify_performance_issues(query_infos, raw_queries)

        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        recommendations = self._generate_optimization_recommendations(
            len(query_infos), avg_time, common_patterns
        )

        return SlowQueryAnalysis(
            total_slow_queries=len(query_infos),
            slowest_query=query_infos[0] if query_infos else None,
            average_execution_time=avg_time,
            common_patterns=common_patterns,
            index_suggestions=index_suggestions,
            performance_issues=performance_issues,
            recommendations=recommendations
        )

    def _extract_query_pattern(self, sql_text: str) -> str:
        """æå–æŸ¥è¯¢æ¨¡å¼å­—ç¬¦ä¸²"""
        return sql_text.replace(' ', '').replace('\n', '').replace('\t', '').upper()[:100]

    def _generate_index_suggestions(self, query_infos: List[SlowQueryInfo]) -> List[IndexSuggestion]:
        """ç”Ÿæˆç´¢å¼•ä¼˜åŒ–å»ºè®®"""
        suggestions = []

        for query in query_infos:
            if not query.uses_index and query.execution_time > 1:
                upper_sql = query.sql_text.upper()

                if 'WHERE' in upper_sql and '=' in upper_sql:
                    table_match = re.search(r'FROM\s+(\w+)', query.sql_text, re.IGNORECASE)
                    table = table_match.group(1) if table_match else 'unknown_table'

                    # æ ¹æ®WHEREæ¡ä»¶ç”Ÿæˆä¸åŒçš„ç´¢å¼•å»ºè®®
                    columns = []
                    priority = 'MEDIUM'
                    expected_improvement = '60-85%'

                    if 'WHERE ID =' in upper_sql or 'WHERE USER_ID =' in upper_sql:
                        columns = ['id']
                        priority = 'HIGH'
                        expected_improvement = '70-90%'
                    elif 'WHERE EMAIL =' in upper_sql:
                        columns = ['email']
                        priority = 'MEDIUM'
                    elif 'WHERE STATUS =' in upper_sql:
                        columns = ['status']
                        priority = 'MEDIUM'

                    if columns:
                        suggestions.append(IndexSuggestion(
                            table=table,
                            columns=columns,
                            index_type='INDEX',
                            expected_improvement=expected_improvement,
                            priority=priority,
                            reason=f"WHEREå­å¥ä¸­é¢‘ç¹ä½¿ç”¨{','.join(columns)}å­—æ®µè¿›è¡ŒæŸ¥è¯¢"
                        ))

                    # å¤åˆç´¢å¼•å»ºè®®
                    if 'WHERE' in upper_sql and (
                        upper_sql.count('AND') > 1 or
                        'ORDER BY' in upper_sql or
                        'GROUP BY' in upper_sql
                    ):
                        composite_columns = self._extract_composite_columns(upper_sql)
                        if len(composite_columns) > 1:
                            suggestions.append(IndexSuggestion(
                                table=table,
                                columns=composite_columns,
                                index_type='INDEX',
                                expected_improvement='70-95%',
                                priority='HIGH',
                                reason='å¤šæ¡ä»¶æŸ¥è¯¢ï¼Œå¤åˆç´¢å¼•å¯æ˜¾è‘—æå‡æ€§èƒ½'
                            ))

        return suggestions

    def _extract_composite_columns(self, upper_sql: str) -> List[str]:
        """æå–å¤åˆç´¢å¼•åˆ—"""
        columns = []
        where_clause = upper_sql.split('WHERE')[1].split('ORDER BY')[0].split('GROUP BY')[0] if 'WHERE' in upper_sql else ''

        # æå–WHEREå­å¥ä¸­çš„å­—æ®µ
        field_pattern = r'(\w+)\s*[=!><]'
        matches = re.findall(field_pattern, where_clause)

        for field in matches:
            if field.upper() not in ['AND', 'OR', 'NOT', 'IS', 'NULL', 'EXISTS', 'IN']:
                if field not in columns:
                    columns.append(field.lower())
                    if len(columns) >= 3:  # æœ€å¤š3ä¸ªå­—æ®µ
                        break

        return columns

    def _identify_performance_issues(self, query_infos: List[SlowQueryInfo], raw_queries: List[Dict[str, Any]]) -> List[str]:
        """è¯†åˆ«æ€§èƒ½é—®é¢˜"""
        issues = []

        no_index_queries = len([q for q in query_infos if not q.uses_index])
        if no_index_queries > len(query_infos) * 0.5:
            issues.append(f"å¤§é‡æŸ¥è¯¢æœªä½¿ç”¨ç´¢å¼• ({no_index_queries}/{len(query_infos)})")

        total_rows_examined = sum(q.rows_examined for q in query_infos)
        avg_rows_examined = total_rows_examined / len(query_infos) if query_infos else 0

        if avg_rows_examined > 10000:
            issues.append(f"å¹³å‡æ‰«æè¡Œæ•°è¿‡é«˜ ({int(avg_rows_examined)}è¡Œ)")

        long_running_queries = len([q for q in query_infos if q.execution_time > 5])
        if long_running_queries > 0:
            issues.append(f"å‘ç°{long_running_queries}ä¸ªæ‰§è¡Œæ—¶é—´è¶…è¿‡5ç§’çš„æŸ¥è¯¢")

        high_lock_time_queries = len([q for q in query_infos if q.lock_time > 1])
        if high_lock_time_queries > 0:
            issues.append(f"å‘ç°{high_lock_time_queries}ä¸ªé”ç­‰å¾…æ—¶é—´è¾ƒé•¿çš„æŸ¥è¯¢")

        return issues

    def _generate_optimization_recommendations(
        self,
        total_queries: int,
        avg_time: float,
        common_patterns: List[Dict[str, Any]]
    ) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []

        if avg_time > 2:
            recommendations.append("âš¡ æŸ¥è¯¢å¹³å‡æ‰§è¡Œæ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®æ£€æŸ¥æ•°æ®åº“å‚æ•°è°ƒä¼˜")

        if len(common_patterns) > 3:
            recommendations.append("ğŸ”„ å‘ç°é‡å¤æŸ¥è¯¢æ¨¡å¼ï¼Œè€ƒè™‘ä½¿ç”¨æŸ¥è¯¢ç¼“å­˜æˆ–å­˜å‚¨è¿‡ç¨‹")

        if total_queries > 50:
            recommendations.append("ğŸ“Š æ…¢æŸ¥è¯¢æ•°é‡è¾ƒå¤šï¼Œå»ºè®®å¯ç”¨æ…¢æŸ¥è¯¢æ—¥å¿—è¿›è¡Œè¯¦ç»†åˆ†æ")

        if total_queries > 10:
            recommendations.append("ğŸ” å‘ç°å¤šä¸ªæ…¢æŸ¥è¯¢ï¼Œå»ºè®®æ·»åŠ é€‚å½“ç´¢å¼•")

        if not recommendations:
            recommendations.append("âœ… æŸ¥è¯¢æ€§èƒ½ç›¸å¯¹è‰¯å¥½ï¼Œå»ºè®®ç»§ç»­ç›‘æ§")

        return recommendations


# =============================================================================
# ç´¢å¼•ä¼˜åŒ–æ¨¡å—
# =============================================================================

class IndexOptimizationModule:
    """
    ç´¢å¼•ä¼˜åŒ–æ¨¡å—

    ä¸“é—¨ç”¨äºåˆ†ææ•°æ®åº“ç´¢å¼•ä½¿ç”¨æƒ…å†µå¹¶ç”Ÿæˆä¼˜åŒ–å»ºè®®çš„æ¨¡å—ã€‚é€šè¿‡åˆ†ææ…¢æŸ¥è¯¢æ¨¡å¼ã€
    ç°æœ‰ç´¢å¼•ä½¿ç”¨æƒ…å†µå’Œè¡¨ç»“æ„ï¼Œæä¾›é’ˆå¯¹æ€§çš„ç´¢å¼•åˆ›å»ºå»ºè®®ï¼Œä»¥æå‡æŸ¥è¯¢æ€§èƒ½ã€‚
    """

    def __init__(self, mysql_manager: MySQLManager, config: PerformanceAnalysisConfig = None):
        """åˆå§‹åŒ–ç´¢å¼•ä¼˜åŒ–æ¨¡å—"""
        self.mysql_manager = mysql_manager
        self.config = config or PerformanceAnalysisConfig()

    async def generate_index_suggestions(self, limit: int = 50, time_range: str = '1 day') -> List[IndexSuggestion]:
        """
        ç”Ÿæˆç´¢å¼•ä¼˜åŒ–å»ºè®®

        é€šè¿‡åˆ†ææ…¢æŸ¥è¯¢æ¨¡å¼å’Œç°æœ‰ç´¢å¼•ä½¿ç”¨æƒ…å†µï¼Œç”Ÿæˆé’ˆå¯¹æ€§çš„ç´¢å¼•åˆ›å»ºå»ºè®®ã€‚

        Args:
            limit: é™åˆ¶è¿”å›çš„å»ºè®®æ•°é‡ï¼Œé»˜è®¤ä¸º50
            time_range: åˆ†ææ—¶é—´èŒƒå›´ï¼Œé»˜è®¤ä¸º1å¤©

        Returns:
            List[IndexSuggestion]: ç´¢å¼•ä¼˜åŒ–å»ºè®®åˆ—è¡¨
        """
        try:
            # åˆå§‹åŒ–æ…¢æŸ¥è¯¢åˆ†ææ¨¡å—å®ä¾‹
            slow_query_module = SlowQueryAnalysisModule(self.mysql_manager, self.config)
            slow_query_analysis = await slow_query_module.analyze_slow_queries(limit, time_range)

            if slow_query_analysis.total_slow_queries == 0:
                return self._generate_general_index_recommendations()

            # åŸºäºæ…¢æŸ¥è¯¢æ•°æ®ç”Ÿæˆé’ˆå¯¹æ€§å»ºè®®
            suggestions = []
            analyzed_tables = set()

            if slow_query_analysis.common_patterns:
                for pattern in slow_query_analysis.common_patterns:
                    pattern_suggestions = await self._analyze_query_pattern(pattern["pattern"])
                    for suggestion in pattern_suggestions:
                        if suggestion.table not in analyzed_tables:
                            suggestions.append(suggestion)
                            analyzed_tables.add(suggestion.table)

            # åˆ†æç°æœ‰ç´¢å¼•ä½¿ç”¨æƒ…å†µ
            existing_index_analysis = await self._analyze_existing_indexes()
            suggestions.extend(existing_index_analysis)

            return suggestions[:limit]

        except Exception as e:
            raise MySQLMCPError(
                f"ç´¢å¼•å»ºè®®ç”Ÿæˆå¤±è´¥: {str(e)}",
                ErrorCategory.SLOW_QUERY_INDEX_SUGGESTION_ERROR,
                ErrorSeverity.MEDIUM
            )

    async def _analyze_query_pattern(self, pattern: str) -> List[IndexSuggestion]:
        """åˆ†ææŸ¥è¯¢æ¨¡å¼"""
        suggestions = []

        try:
            if 'FROM' in pattern and 'WHERE' in pattern:
                table_match = re.search(r'FROM\s+(\w+)', pattern, re.IGNORECASE)
                if table_match:
                    table_name = table_match.group(1)

                    # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
                    if await self._check_table_exists(table_name):
                        # åˆ†æWHEREæ¡ä»¶ä¸­çš„å­—æ®µ
                        field_suggestions = self._extract_field_suggestions(pattern, table_name)
                        suggestions.extend(field_suggestions)
        except Exception:
            # å¿½ç•¥åˆ†æé”™è¯¯ï¼Œç»§ç»­ä¸‹ä¸€ä¸ªæ¨¡å¼
            pass

        return suggestions

    async def _check_table_exists(self, table_name: str) -> bool:
        """æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨"""
        try:
            query = f"SHOW TABLES LIKE '{table_name}'"
            result = await self.mysql_manager.execute_query(query)
            return bool(result)
        except Exception:
            return False

    def _extract_field_suggestions(self, pattern: str, table_name: str) -> List[IndexSuggestion]:
        """æå–å­—æ®µå»ºè®®"""
        suggestions = []
        upper_pattern = pattern.upper()

        # åˆ†æç›¸ç­‰æŸ¥è¯¢
        equal_conditions = re.findall(r'(\w+)\s*[=!]\s*[?\w]+', upper_pattern)
        for condition in equal_conditions[:5]:  # é™åˆ¶å»ºè®®æ•°é‡
            field = condition
            if field.upper() not in ['AND', 'OR', 'NOT', 'IS', 'NULL', 'EXISTS', 'IN']:
                suggestions.append(IndexSuggestion(
                    table=table_name,
                    columns=[field.lower()],
                    index_type='INDEX',
                    expected_improvement='50-80%',
                    priority=self._get_priority(field),
                    reason=f"WHEREæ¡ä»¶ä¸­é¢‘ç¹ä½¿ç”¨{field}å­—æ®µè¿›è¡Œç­‰å€¼æŸ¥è¯¢"
                ))

        # åˆ†æèŒƒå›´æŸ¥è¯¢
        range_conditions = re.findall(r'(\w+)\s*[><]\s*=?\s*[?\w]+', upper_pattern)
        for condition in range_conditions[:3]:
            field = condition
            suggestions.append(IndexSuggestion(
                table=table_name,
                columns=[field.lower()],
                index_type='INDEX',
                expected_improvement='40-70%',
                priority='MEDIUM',
                reason=f"{field}å­—æ®µçš„èŒƒå›´æŸ¥è¯¢å¯é€šè¿‡ç´¢å¼•ä¼˜åŒ–"
            ))

        return suggestions

    def _get_priority(self, field: str) -> str:
        """è·å–å­—æ®µä¼˜å…ˆçº§"""
        high_priority_fields = ['id', 'user_id', 'created_at', 'updated_at']
        medium_priority_fields = ['email', 'status', 'category_id']

        if field.lower() in high_priority_fields:
            return 'HIGH'
        elif field.lower() in medium_priority_fields:
            return 'MEDIUM'
        return 'MEDIUM'

    async def _analyze_existing_indexes(self) -> List[IndexSuggestion]:
        """åˆ†æç°æœ‰ç´¢å¼•"""
        suggestions = []

        try:
            # è·å–æ‰€æœ‰è¡¨
            tables = await self.mysql_manager.execute_query('SHOW TABLES')

            for table_row in tables[:20]:  # é™åˆ¶åˆ†æçš„è¡¨æ•°é‡
                table_name = list(table_row.values())[0]

                # æ£€æŸ¥è¡¨çš„ç´¢å¼•
                index_info = await self._get_table_index_info(table_name)
                table_suggestions = await self._analyze_table_index_health(table_name, index_info)
                suggestions.extend(table_suggestions)

        except Exception:
            # å¿½ç•¥ç´¢å¼•åˆ†æé”™è¯¯
            pass

        return suggestions

    async def _get_table_index_info(self, table_name: str) -> List[Dict[str, Any]]:
        """è·å–è¡¨ç´¢å¼•ä¿¡æ¯"""
        query = """
            SELECT
                INDEX_NAME,
                COLUMN_NAME,
                SEQ_IN_INDEX,
                NON_UNIQUE,
                INDEX_TYPE
            FROM INFORMATION_SCHEMA.STATISTICS
            WHERE TABLE_SCHEMA = DATABASE()
                AND TABLE_NAME = %s
            ORDER BY INDEX_NAME, SEQ_IN_INDEX
        """
        return await self.mysql_manager.execute_query(query, [table_name])

    async def _analyze_table_index_health(self, table_name: str, indexes: List[Dict[str, Any]]) -> List[IndexSuggestion]:
        """åˆ†æè¡¨ç´¢å¼•å¥åº·çŠ¶å†µ"""
        suggestions = []

        # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘ä¸»é”®
        has_primary_key = any(idx.get('INDEX_NAME') == 'PRIMARY' for idx in indexes)
        if not has_primary_key:
            suggestions.append(IndexSuggestion(
                table=table_name,
                columns=['id'],  # å‡è®¾ä¸»é”®å­—æ®µåä¸ºid
                index_type='PRIMARY',
                expected_improvement='80-95%',
                priority='HIGH',
                reason='è¡¨ç¼ºå°‘ä¸»é”®ç´¢å¼•ï¼Œè¿™æ˜¯æ•°æ®åº“è®¾è®¡çš„æœ€ä½³å®è·µ'
            ))

        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤ç´¢å¼•
        index_map = {}
        for idx in indexes:
            index_name = idx.get('INDEX_NAME', '')
            column_name = idx.get('COLUMN_NAME', '')
            if index_name not in index_map:
                index_map[index_name] = []
            index_map[index_name].append(column_name)

        for index_name, columns in index_map.items():
            for other_index_name, other_columns in index_map.items():
                if index_name != other_index_name and columns and other_columns:
                    if self._is_redundant_index(columns, other_columns):
                        suggestions.append(IndexSuggestion(
                            table=table_name,
                            columns=columns,
                            index_type='INDEX',
                            expected_improvement='5-10%',
                            priority='LOW',
                            reason=f"ç´¢å¼•{index_name}ä¸{other_index_name}å­˜åœ¨é‡å¤ï¼Œå¯è€ƒè™‘æ¸…ç†"
                        ))

        return suggestions

    def _is_redundant_index(self, columns1: List[str], columns2: List[str]) -> bool:
        """æ£€æŸ¥ç´¢å¼•æ˜¯å¦å†—ä½™"""
        if len(columns1) != len(columns2):
            return False
        return all(col in columns2 for col in columns1)

    def _generate_general_index_recommendations(self) -> List[IndexSuggestion]:
        """ç”Ÿæˆé€šç”¨ç´¢å¼•å»ºè®®"""
        return [
            IndexSuggestion(
                table='general_recommendation',
                columns=['æ ‡å‡†å»ºè®®'],
                index_type='INDEX',
                expected_improvement='N/A',
                priority='MEDIUM',
                reason='å®šæœŸè¿è¡Œæ…¢æŸ¥è¯¢åˆ†æä»¥è·å–é’ˆå¯¹æ€§çš„ç´¢å¼•ä¼˜åŒ–å»ºè®®'
            ),
            IndexSuggestion(
                table='primary_key_check',
                columns=['ä¸»é”®æ£€æŸ¥'],
                index_type='PRIMARY',
                expected_improvement='é«˜',
                priority='HIGH',
                reason='ç¡®ä¿æ‰€æœ‰è¡¨éƒ½å®šä¹‰äº†åˆé€‚çš„ä¸»é”®ç´¢å¼•'
            )
        ]


# =============================================================================
# æŸ¥è¯¢æ€§èƒ½å‰–ææ¨¡å—
# =============================================================================

class QueryProfilingModule:
    """
    æŸ¥è¯¢æ€§èƒ½å‰–ææ¨¡å—

    ä¸“é—¨ç”¨äºåˆ†æå•ä¸ªSQLæŸ¥è¯¢æ€§èƒ½çš„æ¨¡å—ï¼Œé€šè¿‡æ‰§è¡ŒEXPLAINå‘½ä»¤åˆ†ææŸ¥è¯¢æ‰§è¡Œè®¡åˆ’ï¼Œ
    æä¾›è¯¦ç»†çš„æ€§èƒ½åˆ†ææŠ¥å‘Šå’Œä¼˜åŒ–å»ºè®®ã€‚å¸®åŠ©è¯†åˆ«æŸ¥è¯¢ä¸­çš„æ€§èƒ½ç“¶é¢ˆå’Œæ”¹è¿›æœºä¼šã€‚
    """

    def __init__(self, mysql_manager: MySQLManager):
        """åˆå§‹åŒ–æŸ¥è¯¢æ€§èƒ½å‰–ææ¨¡å—"""
        self.mysql_manager = mysql_manager

    async def profile_query(self, sql: str, params: Optional[List[Any]] = None) -> QueryProfileResult:
        """
        å¯¹ç‰¹å®šæŸ¥è¯¢è¿›è¡Œæ€§èƒ½å‰–æ

        é€šè¿‡æ‰§è¡ŒEXPLAINå‘½ä»¤åˆ†ææŸ¥è¯¢æ‰§è¡Œè®¡åˆ’ï¼Œè¯„ä¼°æŸ¥è¯¢æ€§èƒ½å¹¶æä¾›ä¼˜åŒ–å»ºè®®ã€‚

        Args:
            sql: è¦å‰–æçš„SQLæŸ¥è¯¢è¯­å¥
            params: æŸ¥è¯¢å‚æ•°æ•°ç»„

        Returns:
            QueryProfileResult: æŸ¥è¯¢æ€§èƒ½å‰–æç»“æœ
        """
        try:
            # éªŒè¯æŸ¥è¯¢
            await self.mysql_manager.validate_input(sql, 'query')

            # æ‰§è¡ŒEXPLAINåˆ†æ
            explain_result = await self._get_explain_result(sql, params)

            # è·å–æ‰§è¡Œç»Ÿè®¡ï¼ˆå¦‚æœå¯èƒ½ï¼‰
            execution_stats = await self._get_execution_stats(sql, params)

            # åˆ†ææ‰§è¡Œè®¡åˆ’å¹¶ç”Ÿæˆå»ºè®®
            recommendations = self._analyze_explain_result(explain_result)
            performance_score = self._calculate_performance_score(explain_result, execution_stats)

            return QueryProfileResult(
                explain_result=explain_result,
                execution_stats=execution_stats,
                recommendations=recommendations,
                performance_score=performance_score
            )

        except Exception as e:
            raise MySQLMCPError(
                f"æŸ¥è¯¢æ€§èƒ½å‰–æå¤±è´¥: {str(e)}",
                ErrorCategory.DATA_ERROR,
                ErrorSeverity.MEDIUM
            )

    async def _get_explain_result(self, sql: str, params: Optional[List[Any]] = None) -> List[Dict[str, Any]]:
        """è·å–EXPLAINç»“æœ"""
        try:
            # å°è¯•ä½¿ç”¨EXPLAIN FORMAT=JSON
            explain_query = f"EXPLAIN FORMAT=JSON {sql}"
            result = await self.mysql_manager.execute_query(explain_query, params)
            return result if isinstance(result, list) else [result]
        except Exception:
            # å¦‚æœFORMAT=JSONä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»Ÿæ ¼å¼
            explain_query = f"EXPLAIN {sql}"
            result = await self.mysql_manager.execute_query(explain_query, params)
            return result if isinstance(result, list) else [result]

    async def _get_execution_stats(self, sql: str, params: Optional[List[Any]] = None) -> Dict[str, Any]:
        """è·å–æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯"""
        try:
            # å¯ç”¨æŸ¥è¯¢æ€§èƒ½åˆ†æ
            await self.mysql_manager.execute_query('SET profiling = 1')

            # æ‰§è¡ŒæŸ¥è¯¢
            await self.mysql_manager.execute_query(sql, params)

            # è·å–æ€§èƒ½åˆ†æä¿¡æ¯
            profile_result = await self.mysql_manager.execute_query('SHOW PROFILE')

            # è®¡ç®—æ€»æ‰§è¡Œæ—¶é—´
            total_duration = sum(float(row.get('Duration', 0)) for row in profile_result) if profile_result else 0

            return {
                'execution_time': total_duration * 1000,  # è½¬æ¢ä¸ºæ¯«ç§’
                'rows_examined': -1,  # EXPLAINä¸­è·å–æ›´å‡†ç¡®çš„ä¿¡æ¯
                'rows_returned': -1   # EXPLAINä¸­è·å–æ›´å‡†ç¡®çš„ä¿¡æ¯
            }

        except Exception:
            return {
                'execution_time': -1,
                'rows_examined': -1,
                'rows_returned': -1
            }

    def _analyze_explain_result(self, explain_result: List[Dict[str, Any]]) -> List[str]:
        """åˆ†æEXPLAINç»“æœå¹¶ç”Ÿæˆå»ºè®®"""
        recommendations = []

        try:
            for i, row in enumerate(explain_result):
                # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†å…¨è¡¨æ‰«æ
                if row.get('type') == 'ALL':
                    recommendations.append(f"æŸ¥è¯¢æ­¥éª¤{i + 1}ï¼šä½¿ç”¨å…¨è¡¨æ‰«æï¼Œå»ºè®®æ·»åŠ ç´¢å¼•")

                # æ£€æŸ¥ç´¢å¼•ä½¿ç”¨æƒ…å†µ
                if not row.get('key'):
                    recommendations.append(f"æŸ¥è¯¢æ­¥éª¤{i + 1}ï¼šæœªä½¿ç”¨ç´¢å¼•ï¼ŒæŸ¥è¯¢æ€§èƒ½å¯èƒ½è¾ƒå·®")

                # æ£€æŸ¥æ‰«æè¡Œæ•°
                rows = row.get('rows')
                if rows and rows > 1000:
                    recommendations.append(f"æŸ¥è¯¢æ­¥éª¤{i + 1}ï¼šæ‰«æ{rows}è¡Œæ•°æ®ï¼Œå»ºè®®ä¼˜åŒ–ç´¢å¼•æˆ–æŸ¥è¯¢æ¡ä»¶")

                # æ£€æŸ¥Extraå­—æ®µçš„å…³é”®ä¿¡æ¯
                extra = row.get('Extra', '')
                if extra:
                    if 'Using temporary' in extra:
                        recommendations.append(f"æŸ¥è¯¢æ­¥éª¤{i + 1}ï¼šä½¿ç”¨ä¸´æ—¶è¡¨ï¼Œå»ºè®®ä¼˜åŒ–GROUP BYæˆ–ORDER BY")
                    if 'Using filesort' in extra:
                        recommendations.append(f"æŸ¥è¯¢æ­¥éª¤{i + 1}ï¼šä½¿ç”¨æ–‡ä»¶æ’åºï¼Œå»ºè®®ä¼˜åŒ–ORDER BYç´¢å¼•")
                    if 'Using where' in extra:
                        recommendations.append(f"æŸ¥è¯¢æ­¥éª¤{i + 1}ï¼šä½¿ç”¨WHEREæ¡ä»¶è¿‡æ»¤ï¼Œç´¢å¼•æ¨èæœ‰æ•ˆ")
                    if 'Using index' in extra:
                        recommendations.append(f"æŸ¥è¯¢æ­¥éª¤{i + 1}ï¼šä½¿ç”¨è¦†ç›–ç´¢å¼•ï¼ŒæŸ¥è¯¢æ€§èƒ½è‰¯å¥½")

                # æ£€æŸ¥possible_keyså­—æ®µ
                possible_keys = row.get('possible_keys', [])
                if not possible_keys:
                    recommendations.append(f"æŸ¥è¯¢æ­¥éª¤{i + 1}ï¼šæ²¡æœ‰å¯ç”¨çš„ç´¢å¼•ï¼Œå»ºè®®ä¸ºæŸ¥è¯¢æ¡ä»¶æ·»åŠ ç´¢å¼•")

            # å¦‚æœæ²¡æœ‰å…·ä½“çš„å»ºè®®ï¼Œæä¾›é€šç”¨å»ºè®®
            if not recommendations:
                recommendations.append('æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’æ­£å¸¸ï¼Œå»ºè®®ç»§ç»­ç›‘æ§æ€§èƒ½è¡¨ç°')

            # æ·»åŠ æ ‡å‡†çš„ä¼˜åŒ–å»ºè®®
            full_table_scans = [row for row in explain_result if row.get('type') == 'ALL' and row.get('rows', 0) > 1000]
            if full_table_scans:
                recommendations.append('è€ƒè™‘ä¸ºç›¸å…³å­—æ®µæ·»åŠ ç´¢å¼•ä»¥å‡å°‘å…¨è¡¨æ‰«æ')

            if len(explain_result) > 3:
                recommendations.append('æŸ¥è¯¢æ¶‰åŠå¤šä¸ªè¡¨ï¼Œå»ºè®®æ£€æŸ¥JOINæ¡ä»¶å’Œç´¢å¼•')

        except Exception as e:
            recommendations.append(f"åˆ†æè§£é‡Šç»“æœæ—¶å‡ºç°é”™è¯¯: {str(e)}")

        return recommendations

    def _calculate_performance_score(self, explain_result: List[Dict[str, Any]], execution_stats: Dict[str, Any]) -> float:
        """è®¡ç®—æ€§èƒ½è¯„åˆ†"""
        try:
            score = 100.0

            # åŸºäºå®é™…æ‰§è¡Œæ—¶é—´æ‰“åˆ†
            if execution_stats.get('execution_time') != -1:
                exec_time = execution_stats['execution_time']
                if exec_time > 5000:
                    score -= 50  # 5ç§’ä»¥ä¸Šä¸¥é‡å‡åˆ†
                elif exec_time > 1000:
                    score -= 30  # 1ç§’ä»¥ä¸Šå‡åˆ†
                elif exec_time > 500:
                    score -= 15  # 500msä»¥ä¸Šå°å¹…å‡åˆ†
                elif exec_time < 50:
                    score += 10  # å¿«æŸ¥è¯¢åŠ åˆ†
            else:
                # åŸºäºæ‰§è¡Œè®¡åˆ’ä¼°ç®—åˆ†æ•°
                for row in explain_result:
                    # å…¨è¡¨æ‰«æä¸¥é‡å‡åˆ†
                    if row.get('type') == 'ALL':
                        score -= 30
                    # å¤§é‡æ‰«æè¡Œæ•°å‡åˆ†
                    if row.get('rows', 0) > 10000:
                        score -= 20
                    # ç´¢å¼•æ‰«ææƒ…å†µ
                    if row.get('key'):
                        score += 10

            return max(0.0, min(100.0, score))

        except Exception:
            return 50.0  # æ— æ³•åˆ†ææ—¶è¿”å›ä¸­ç­‰åˆ†æ•°


# =============================================================================
# æ€§èƒ½ç›‘æ§æ¨¡å—
# =============================================================================

class PerformanceMonitoringModule:
    """
    æ€§èƒ½ç›‘æ§æ¨¡å—

    ç”¨äºæŒç»­ç›‘æ§MySQLæ•°æ®åº“æ€§èƒ½çš„æ¨¡å—ï¼Œå®šæœŸåˆ†ææ…¢æŸ¥è¯¢å¹¶æä¾›å®æ—¶æ€§èƒ½åé¦ˆã€‚
    æ”¯æŒé…ç½®ç›‘æ§é—´éš”å’Œè‡ªåŠ¨å‘Šè­¦åŠŸèƒ½ï¼Œå¸®åŠ©åŠæ—¶å‘ç°å’Œè§£å†³æ€§èƒ½é—®é¢˜ã€‚
    """

    def __init__(self, mysql_manager: MySQLManager, config: PerformanceAnalysisConfig = None):
        """åˆå§‹åŒ–æ€§èƒ½ç›‘æ§æ¨¡å—"""
        self.mysql_manager = mysql_manager
        self.slow_query_analysis = SlowQueryAnalysisModule(mysql_manager, config)
        self.monitoring_active = False
        self.monitoring_interval = None

    async def start_monitoring(self, config: SlowQueryConfig = None, interval_minutes: int = 60) -> None:
        """
        å¯åŠ¨æ€§èƒ½ç›‘æ§

        å¯åŠ¨å®šæœŸæ€§èƒ½ç›‘æ§ä»»åŠ¡ï¼ŒæŒ‰æŒ‡å®šé—´éš”åˆ†ææ…¢æŸ¥è¯¢å¹¶æä¾›æ€§èƒ½åé¦ˆã€‚

        Args:
            config: æ…¢æŸ¥è¯¢é…ç½®é€‰é¡¹
            interval_minutes: ç›‘æ§é—´éš”ï¼ˆåˆ†é’Ÿï¼‰ï¼Œé»˜è®¤ä¸º60åˆ†é’Ÿ
        """
        try:
            # å¯ç”¨æ…¢æŸ¥è¯¢æ—¥å¿—
            if config:
                await self.slow_query_analysis.enable_slow_query_log(config)

            self.monitoring_active = True

            # è®¾ç½®å®šæœŸç›‘æ§
            self.monitoring_interval = asyncio.create_task(self._monitoring_loop(interval_minutes))

            logger.info(f"ğŸ” [æ€§èƒ½ç›‘æ§] å¼€å§‹ç›‘æ§ï¼Œæ¯ {interval_minutes} åˆ†é’Ÿåˆ†æä¸€æ¬¡")

        except Exception as e:
            raise MySQLMCPError(
                f"å¯åŠ¨æ€§èƒ½ç›‘æ§å¤±è´¥: {str(e)}",
                ErrorCategory.SLOW_QUERY_MONITORING_ERROR,
                ErrorSeverity.HIGH
            )

    async def _monitoring_loop(self, interval_minutes: int) -> None:
        """ç›‘æ§å¾ªç¯"""
        try:
            while self.monitoring_active:
                await asyncio.sleep(interval_minutes * 60)  # è½¬æ¢ä¸ºç§’

                if not self.monitoring_active:
                    break

                try:
                    analysis = await self.slow_query_analysis.analyze_slow_queries(20, '1 hour')

                    if analysis.total_slow_queries > 0:
                        logger.warning(f"âš ï¸ [æ€§èƒ½ç›‘æ§] æ£€æµ‹åˆ° {analysis.total_slow_queries} ä¸ªæ…¢æŸ¥è¯¢")
                        logger.warning(f"ğŸ“Š [æ€§èƒ½ç›‘æ§] æœ€æ…¢æŸ¥è¯¢è€—æ—¶: {analysis.slowest_query.execution_time:.2f}s" if analysis.slowest_query else "N/A")

                        if analysis.index_suggestions:
                            logger.warning(f"ğŸ’¡ [æ€§èƒ½ç›‘æ§] å‘ç° {len(analysis.index_suggestions)} ä¸ªç´¢å¼•ä¼˜åŒ–å»ºè®®")
                    else:
                        logger.info("âœ… [æ€§èƒ½ç›‘æ§] æŸ¥è¯¢æ€§èƒ½æ­£å¸¸")

                except Exception as e:
                    logger.error(f"âŒ [æ€§èƒ½ç›‘æ§] ç›‘æ§è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {str(e)}")

        except asyncio.CancelledError:
            logger.info("ğŸ”„ [æ€§èƒ½ç›‘æ§] ç›‘æ§å¾ªç¯å·²å–æ¶ˆ")
        except Exception as e:
            logger.error(f"âŒ [æ€§èƒ½ç›‘æ§] ç›‘æ§å¾ªç¯å¼‚å¸¸: {str(e)}")

    def stop_monitoring(self) -> None:
        """åœæ­¢æ€§èƒ½ç›‘æ§"""
        self.monitoring_active = False
        if self.monitoring_interval:
            self.monitoring_interval.cancel()
            self.monitoring_interval = None
        logger.info("â¹ï¸ [æ€§èƒ½ç›‘æ§] æ€§èƒ½ç›‘æ§å·²åœæ­¢")

    def get_monitoring_status(self) -> Dict[str, Any]:
        """è·å–ç›‘æ§çŠ¶æ€"""
        return {
            "active": self.monitoring_active,
            "config": self.slow_query_analysis.config.__dict__ if self.slow_query_analysis.config else {}
        }


# =============================================================================
# æŠ¥å‘Šç”Ÿæˆæ¨¡å—
# =============================================================================

class ReportingModule:
    """
    æŠ¥å‘Šç”Ÿæˆæ¨¡å—

    ä¸“é—¨ç”¨äºç”Ÿæˆç»¼åˆMySQLæ•°æ®åº“æ€§èƒ½æŠ¥å‘Šçš„æ¨¡å—ï¼Œæ•´åˆæ…¢æŸ¥è¯¢åˆ†æã€ç³»ç»ŸçŠ¶æ€ç›‘æµ‹å’Œä¼˜åŒ–å»ºè®®ã€‚
    é€šè¿‡å¤šç»´åº¦æ•°æ®æ”¶é›†å’Œæ·±åº¦åˆ†æï¼Œç”Ÿæˆç»“æ„åŒ–çš„æ€§èƒ½æŠ¥å‘Šå¸®åŠ©æ•°æ®åº“ç®¡ç†å‘˜è¿›è¡Œæ€§èƒ½è¯Šæ–­
    å’Œä¼˜åŒ–å†³ç­–ã€‚æ”¯æŒçµæ´»çš„æŠ¥å‘Šé…ç½®å’Œè¯¦ç»†ç¨‹åº¦æ§åˆ¶ï¼Œæ»¡è¶³ä¸åŒåœºæ™¯çš„æŠ¥å‘Šéœ€æ±‚ã€‚
    """

    def __init__(self, mysql_manager: MySQLManager, config: PerformanceAnalysisConfig = None):
        """åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆæ¨¡å—"""
        self.mysql_manager = mysql_manager
        self.slow_query_analysis = SlowQueryAnalysisModule(mysql_manager, config)

    async def generate_report(self, limit: int = 50, time_range: str = '1 day', include_details: bool = True) -> PerformanceReport:
        """
        ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š

        ç”Ÿæˆç»¼åˆçš„MySQLæ•°æ®åº“æ€§èƒ½æŠ¥å‘Šï¼ŒåŒ…å«æ…¢æŸ¥è¯¢åˆ†æã€ç³»ç»ŸçŠ¶æ€æ£€æŸ¥å’Œä¼˜åŒ–å»ºè®®ã€‚

        Args:
            limit: åˆ†ææŸ¥è¯¢çš„æœ€å¤§æ•°é‡é™åˆ¶
            time_range: æŠ¥å‘Šåˆ†æçš„æ—¶é—´èŒƒå›´
            include_details: æ˜¯å¦åŒ…å«è¯¦ç»†ä¿¡æ¯

        Returns:
            PerformanceReport: å®Œæ•´çš„æ€§èƒ½æŠ¥å‘Šå¯¹è±¡
        """
        try:
            # è·å–æ…¢æŸ¥è¯¢åˆ†æ
            slow_query_analysis = await self.slow_query_analysis.analyze_slow_queries(limit, time_range)

            # è·å–ç³»ç»ŸçŠ¶æ€
            system_status = await self._get_system_status()

            # ç”Ÿæˆä¼˜åŒ–å»ºè®®
            recommendations = self._generate_comprehensive_recommendations(slow_query_analysis, system_status)

            report = PerformanceReport(
                generated_at=datetime.now(),
                summary={
                    "slow_queries_count": slow_query_analysis.total_slow_queries,
                    "average_execution_time": slow_query_analysis.average_execution_time,
                    "recommendations_count": len(recommendations)
                },
                slow_query_analysis=slow_query_analysis,
                system_status=system_status,
                recommendations=recommendations
            )

            return report

        except Exception as e:
            raise MySQLMCPError(
                f"ç”Ÿæˆæ€§èƒ½æŠ¥å‘Šå¤±è´¥: {str(e)}",
                ErrorCategory.SLOW_QUERY_REPORT_GENERATION_ERROR,
                ErrorSeverity.MEDIUM
            )

    async def _get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€ä¿¡æ¯"""
        try:
            # è·å–è¿æ¥ä¿¡æ¯
            connection_query = "SELECT COUNT(*) as active_connections FROM information_schema.processlist WHERE COMMAND != 'Sleep'"
            connection_result = await self.mysql_manager.execute_query(connection_query)
            active_connections = connection_result[0].get('active_connections', 0) if connection_result else 0

            # è·å–ç‰ˆæœ¬ä¿¡æ¯
            version_query = "SELECT VERSION() as mysql_version"
            version_result = await self.mysql_manager.execute_query(version_query)

            return {
                "connection_health": 'healthy' if active_connections < 50 else ('warning' if active_connections < 100 else 'critical'),
                "memory_usage": 'é€šè¿‡ç³»ç»Ÿç›‘æ§è·å–',
                "active_connections": active_connections,
                "system": {
                    "mysql_version": version_result[0].get('mysql_version', 'unknown') if version_result else 'unknown',
                    "query_cache_hit_rate": await self._get_query_cache_hit_rate(),
                    "innodb_buffer_pool_hit_rate": await self._get_innodb_buffer_pool_hit_rate()
                }
            }

        except Exception:
            return {
                "connection_health": 'unknown',
                "memory_usage": 'unknown',
                "active_connections": -1,
                "error": 'ç³»ç»ŸçŠ¶æ€è·å–å¤±è´¥'
            }

    async def _get_query_cache_hit_rate(self) -> str:
        """è·å–æŸ¥è¯¢ç¼“å­˜å‘½ä¸­ç‡"""
        try:
            # æŸ¥è¯¢ç¼“å­˜ç›¸å…³çš„MySQLçŠ¶æ€å˜é‡
            cache_status_query = """
                SHOW GLOBAL STATUS WHERE Variable_name IN (
                    'Qcache_queries_in_cache',
                    'Qcache_hits',
                    'Qcache_inserts',
                    'Qcache_not_cached',
                    'Qcache_lowmem_prunes'
                )
            """
            cache_result = await self.mysql_manager.execute_query(cache_status_query)

            if not cache_result:
                return '0.0%'

            # å°†çŠ¶æ€ç»“æœè½¬æ¢ä¸ºå­—å…¸
            cache_stats = {row['Variable_name']: int(row.get('Value', 0)) for row in cache_result}

            hits = cache_stats.get('Qcache_hits', 0)
            inserts = cache_stats.get('Qcache_inserts', 0)
            not_cached = cache_stats.get('Qcache_not_cached', 0)

            # è®¡ç®—æ€»æŸ¥è¯¢æ•°å’Œå‘½ä¸­ç‡
            total_queries = hits + inserts + not_cached
            if total_queries == 0:
                return '0.0%'

            hit_rate = (hits / total_queries) * 100
            return f"{hit_rate:.1f}%"

        except Exception as e:
            logger.warning(f"è·å–æŸ¥è¯¢ç¼“å­˜å‘½ä¸­ç‡å¤±è´¥: {str(e)}")
            return 'N/A'

    async def _get_innodb_buffer_pool_hit_rate(self) -> str:
        """è·å–InnoDBç¼“å†²æ± å‘½ä¸­ç‡"""
        try:
            # æŸ¥è¯¢InnoDBç›¸å…³çš„MySQLçŠ¶æ€å˜é‡
            innodb_status_query = """
                SHOW GLOBAL STATUS WHERE Variable_name IN (
                    'Innodb_buffer_pool_reads',
                    'Innodb_buffer_pool_read_requests'
                )
            """
            innodb_result = await self.mysql_manager.execute_query(innodb_status_query)

            if not innodb_result:
                return 'N/A'

            # å°†çŠ¶æ€ç»“æœè½¬æ¢ä¸ºå­—å…¸
            innodb_stats = {row['Variable_name']: int(row.get('Value', 0)) for row in innodb_result}

            buffer_reads = innodb_stats.get('Innodb_buffer_pool_reads', 0)
            read_requests = innodb_stats.get('Innodb_buffer_pool_read_requests', 0)

            # è®¡ç®—ç¼“å†²æ± å‘½ä¸­ç‡
            if read_requests == 0:
                return '100.0%'

            hit_rate = ((read_requests - buffer_reads) / read_requests) * 100
            return f"{max(0, hit_rate):.1f}%"

        except Exception as e:
            logger.warning(f"è·å–InnoDBç¼“å†²æ± å‘½ä¸­ç‡å¤±è´¥: {str(e)}")
            return 'N/A'

    def _generate_comprehensive_recommendations(
        self,
        analysis: SlowQueryAnalysis,
        system_status: Dict[str, Any]
    ) -> List[str]:
        """ç”Ÿæˆç»¼åˆä¼˜åŒ–å»ºè®®"""
        recommendations = []

        # åŸºäºæ…¢æŸ¥è¯¢åˆ†æçš„å»ºè®®
        if analysis.recommendations:
            recommendations.extend(analysis.recommendations)

        # ç³»ç»Ÿçº§å»ºè®®
        connection_health = system_status.get('connection_health', 'unknown')
        if connection_health == 'critical':
            recommendations.append('ğŸ”— è¿æ¥æ•°è¿‡é«˜ï¼Œå»ºè®®å¢åŠ è¿æ¥æ± å¤§å°æˆ–ä¼˜åŒ–æŸ¥è¯¢æ•ˆç‡')

        if analysis.total_slow_queries > 100:
            recommendations.append('ğŸ“Š å¤§é‡æ…¢æŸ¥è¯¢å‘ç°ï¼Œå»ºè®®å¯ç”¨æŸ¥è¯¢ç¼“å­˜æˆ–è¿›è¡Œå…¨é¢çš„ç´¢å¼•ä¼˜åŒ–')

        if analysis.average_execution_time > 5:
            recommendations.append('âš¡ å¹³å‡æŸ¥è¯¢æ‰§è¡Œæ—¶é—´è¿‡é•¿ï¼Œå»ºè®®è¿›è¡ŒæœåŠ¡å™¨å‚æ•°è°ƒä¼˜')

        if not recommendations:
            recommendations.append('âœ… ç³»ç»Ÿæ€§èƒ½è‰¯å¥½ï¼Œç»§ç»­ä¿æŒå½“å‰çš„ä¼˜åŒ–æªæ–½')

        return recommendations


# =============================================================================
# ç»Ÿä¸€æ€§èƒ½ç®¡ç†å™¨ç±» - åˆå¹¶æ‰€æœ‰æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½
# =============================================================================

class PerformanceManager:
    """
    ç»Ÿä¸€æ€§èƒ½ç®¡ç†å™¨ç±» - åˆå¹¶æ‰€æœ‰æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½

    ä¼ä¸šçº§MySQLæ€§èƒ½ç®¡ç†çš„æ ¸å¿ƒç»„ä»¶ï¼Œæ•´åˆäº†æ…¢æŸ¥è¯¢åˆ†æã€ç´¢å¼•ä¼˜åŒ–ã€æŸ¥è¯¢å‰–æã€
    æ€§èƒ½ç›‘æ§å’ŒæŠ¥å‘Šç”Ÿæˆç­‰äº”å¤§æ ¸å¿ƒåŠŸèƒ½æ¨¡å—ã€‚æä¾›ç»Ÿä¸€çš„æ€§èƒ½ä¼˜åŒ–å…¥å£å’Œé…ç½®ç®¡ç†ï¼Œ
    æ”¯æŒå¤šç§æ€§èƒ½ä¼˜åŒ–æ“ä½œçš„é›†ä¸­è°ƒåº¦å’Œæ‰§è¡Œã€‚
    """

    def __init__(self, mysql_manager: MySQLManager, config: PerformanceAnalysisConfig = None):
        """
        åˆå§‹åŒ–æ€§èƒ½ç®¡ç†å™¨

        åˆ›å»ºPerformanceManagerå®ä¾‹å¹¶åˆå§‹åŒ–æ‰€æœ‰å­æ¨¡å—ã€‚æ ¹æ®æä¾›çš„é…ç½®å‚æ•°
        è®¾ç½®æ€§èƒ½åˆ†æçš„é»˜è®¤å€¼ï¼Œç¡®ä¿æ‰€æœ‰æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½éƒ½èƒ½æ­£å¸¸å·¥ä½œã€‚

        Args:
            mysql_manager: MySQLè¿æ¥ç®¡ç†å™¨å®ä¾‹
            config: æ€§èƒ½åˆ†æé…ç½®é€‰é¡¹
        """
        self.mysql_manager = mysql_manager
        self.config = config or PerformanceAnalysisConfig(
            long_query_time=1.0,
            time_range=1,
            include_details=True,
            limit=100,
            min_examined_row_limit=1000,
            enable_performance_schema=True,
            log_queries_not_using_indexes=True,
            max_log_file_size=100,
            log_slow_admin_statements=True
        )

        # åˆå§‹åŒ–å­æ¨¡å—
        self.slow_query_analysis = SlowQueryAnalysisModule(mysql_manager, self.config)
        self.index_optimization = IndexOptimizationModule(mysql_manager, self.config)
        self.query_profiling = QueryProfilingModule(mysql_manager)
        self.performance_monitoring = PerformanceMonitoringModule(mysql_manager, self.config)
        self.reporting = ReportingModule(mysql_manager, self.config)

    async def configure_slow_query_log(self, long_query_time: float = 1.0) -> None:
        """
        é…ç½®æ…¢æŸ¥è¯¢æ—¥å¿—

        å¯ç”¨MySQLæ…¢æŸ¥è¯¢æ—¥å¿—åŠŸèƒ½ï¼Œè®¾ç½®æ…¢æŸ¥è¯¢é˜ˆå€¼å’Œå…¶ä»–ç›¸å…³å‚æ•°ã€‚

        Args:
            long_query_time: æ…¢æŸ¥è¯¢æ—¶é—´é˜ˆå€¼ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ä¸º1ç§’
        """
        try:
            settings = [
                'SET GLOBAL slow_query_log = "ON"',
                f'SET GLOBAL long_query_time = {long_query_time}',
                'SET GLOBAL log_queries_not_using_indexes = "ON"',
                'SET GLOBAL log_slow_admin_statements = "ON"'
            ]

            for setting in settings:
                await self.mysql_manager.execute_query(setting)

            logger.info(f"âœ… æ…¢æŸ¥è¯¢æ—¥å¿—å·²é…ç½®ï¼Œé˜ˆå€¼: {long_query_time}ç§’")

        except Exception as e:
            raise MySQLMCPError(
                f"é…ç½®æ…¢æŸ¥è¯¢æ—¥å¿—å¤±è´¥: {str(e)}",
                ErrorCategory.CONFIGURATION_ERROR,
                ErrorSeverity.HIGH
            )

    async def get_slow_query_log_config(self) -> Dict[str, Any]:
        """è·å–æ…¢æŸ¥è¯¢æ—¥å¿—é…ç½®"""
        try:
            queries = [
                'SELECT @@slow_query_log as enabled',
                'SELECT @@long_query_time as threshold',
                'SELECT @@slow_query_log_file as log_file',
                'SELECT @@log_queries_not_using_indexes as log_no_index'
            ]

            config = {}
            for query in queries:
                result = await self.mysql_manager.execute_query(query)
                if result:
                    config.update(result[0])

            return config

        except Exception as e:
            raise MySQLMCPError(
                f"è·å–æ…¢æŸ¥è¯¢æ—¥å¿—é…ç½®å¤±è´¥: {str(e)}",
                ErrorCategory.DATA_ERROR,
                ErrorSeverity.LOW
            )

    async def disable_slow_query_log(self) -> None:
        """ç¦ç”¨æ…¢æŸ¥è¯¢æ—¥å¿—"""
        try:
            await self.mysql_manager.execute_query('SET GLOBAL slow_query_log = "OFF"')
            logger.info("â¹ï¸ æ…¢æŸ¥è¯¢æ—¥å¿—å·²ç¦ç”¨")
        except Exception as e:
            raise MySQLMCPError(
                f"ç¦ç”¨æ…¢æŸ¥è¯¢æ—¥å¿—å¤±è´¥: {str(e)}",
                ErrorCategory.CONFIGURATION_ERROR,
                ErrorSeverity.LOW
            )

    async def optimize_performance(
        self,
        action: str,
        options: Dict[str, Any] = None
    ) -> Any:
        """
        ç»Ÿä¸€æ€§èƒ½ä¼˜åŒ–å…¥å£æ–¹æ³•

        æ€§èƒ½ç®¡ç†å™¨çš„æ ¸å¿ƒæ–¹æ³•ï¼Œæ ¹æ®æŒ‡å®šçš„æ“ä½œç±»å‹è°ƒç”¨ç›¸åº”çš„å­æ¨¡å—æ–¹æ³•æ‰§è¡Œå…·ä½“åŠŸèƒ½ã€‚

        Args:
            action: è¦æ‰§è¡Œçš„æ€§èƒ½ä¼˜åŒ–æ“ä½œç±»å‹
            options: æ“ä½œé€‰é¡¹å‚æ•°

        Returns:
            æ“ä½œç»“æœï¼Œæ ¹æ®æ“ä½œç±»å‹è¿”å›ä¸åŒç»“æ„çš„æ•°æ®
        """
        if options is None:
            options = {}

        try:
            match action:
                case 'analyze_slow_queries':
                    return await self.slow_query_analysis.analyze_slow_queries(
                        options.get('limit', 100),
                        options.get('time_range', '1 day')
                    )

                case 'suggest_indexes':
                    return await self.index_optimization.generate_index_suggestions(
                        options.get('limit', 50),
                        options.get('time_range', '1 day')
                    )

                case 'performance_report':
                    return await self.reporting.generate_report(
                        options.get('limit', 50),
                        options.get('time_range', '1 day'),
                        options.get('include_details', True)
                    )

                case 'query_profiling':
                    if 'query' not in options:
                        raise MySQLMCPError(
                            'query_profilingæ“ä½œå¿…é¡»æä¾›queryå‚æ•°',
                            ErrorCategory.INVALID_INPUT,
                            ErrorSeverity.MEDIUM
                        )
                    return await self.query_profiling.profile_query(
                        options['query'],
                        options.get('params')
                    )

                case 'start_monitoring':
                    config = None
                    if 'long_query_time' in options or 'log_queries_not_using_indexes' in options:
                        config = SlowQueryConfig(
                            long_query_time=options.get('long_query_time'),
                            log_queries_not_using_indexes=options.get('log_queries_not_using_indexes')
                        )
                    await self.performance_monitoring.start_monitoring(
                        config,
                        options.get('monitoring_interval_minutes', 60)
                    )
                    return {'message': 'æ€§èƒ½ç›‘æ§å·²å¯åŠ¨'}

                case 'stop_monitoring':
                    self.performance_monitoring.stop_monitoring()
                    return {'message': 'æ€§èƒ½ç›‘æ§å·²åœæ­¢'}

                case 'enable_slow_query_log':
                    await self.configure_slow_query_log(options.get('long_query_time', 1.0))
                    return {'message': 'æ…¢æŸ¥è¯¢æ—¥å¿—å·²å¯ç”¨'}

                case 'disable_slow_query_log':
                    await self.disable_slow_query_log()
                    return {'message': 'æ…¢æŸ¥è¯¢æ—¥å¿—å·²ç¦ç”¨'}

                case 'get_active_slow_queries':
                    return await self.slow_query_analysis.get_active_slow_queries()

                case 'get_config':
                    return await self.get_slow_query_log_config()

                case _:
                    raise MySQLMCPError(
                        f"æœªçŸ¥çš„æ€§èƒ½ä¼˜åŒ–æ“ä½œ: {action}",
                        ErrorCategory.INVALID_INPUT,
                        ErrorSeverity.MEDIUM
                    )

        except Exception as e:
            raise MySQLMCPError(
                f"æ€§èƒ½ä¼˜åŒ–æ“ä½œå¤±è´¥: {str(e)}",
                ErrorCategory.UNKNOWN,
                ErrorSeverity.MEDIUM
            )